{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMq4yGxNMwWVIZhYYIOm4cV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jagsir346/Mini-Project-22-Cosine-Similarity/blob/main/Mini_Project_22_Cosine_Similarity.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bHQ5LJ329Hhe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68ea595c-8515-422e-da0c-fa8f51aaae72"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          Arthur       Ben     Clark\n",
            "Arthur  1.000000  0.258615  0.258615\n",
            "Ben     0.258615  1.000000  0.258615\n",
            "Clark   0.258615  0.258615  1.000000\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Sample documents\n",
        "documents = [\n",
        "    \"Arthur.txt\",\n",
        "    \"Ben.txt\",\n",
        "    \"Clark.txt\"\n",
        "]\n",
        "\n",
        "# Create TF-IDF matrix\n",
        "vectorizer = TfidfVectorizer()\n",
        "tfidf_matrix = vectorizer.fit_transform(documents)\n",
        "\n",
        "# Compute cosine similarity\n",
        "cosine_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n",
        "\n",
        "# Display results\n",
        "import pandas as pd\n",
        "df = pd.DataFrame(cosine_sim, index=['Arthur', 'Ben', 'Clark'], columns=['Arthur', 'Ben', 'Clark'])\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import pandas as pd\n",
        "\n",
        "# Load and clean the text\n",
        "def clean_text(text):\n",
        "    text = text.lower()  # Lowercase\n",
        "    text = re.sub(r'[^\\w\\s]', '', text)  # Remove punctuation\n",
        "    return text\n",
        "\n",
        "with open('Ben.txt', 'r', encoding='utf-8') as f1, \\\n",
        "     open('Arthur.txt', 'r', encoding='utf-8') as f2, \\\n",
        "     open('Clark.txt', 'r', encoding='utf-8') as f3:\n",
        "    docs = [clean_text(f1.read()), clean_text(f2.read()), clean_text(f3.read())]\n",
        "\n",
        "# Vectorize with stopwords\n",
        "vectorizer = TfidfVectorizer(stop_words='english')\n",
        "tfidf_matrix = vectorizer.fit_transform(docs)\n",
        "\n",
        "# Compute similarity\n",
        "cos_sim = cosine_similarity(tfidf_matrix)\n",
        "\n",
        "# Display\n",
        "df = pd.DataFrame(cos_sim, index=['Ben', 'Arthur', 'Clark'], columns=['Ben', 'Arthur', 'Clark'])\n",
        "print(df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qM3r3OeJIMab",
        "outputId": "5d19baab-51be-4a92-8ea1-81dd0f5221bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             Ben    Arthur     Clark\n",
            "Ben     1.000000  0.250531  0.128281\n",
            "Arthur  0.250531  1.000000  0.382365\n",
            "Clark   0.128281  0.382365  1.000000\n"
          ]
        }
      ]
    }
  ]
}